{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UniProt_id', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '312', '313', '314', '315', '316', '317', '318', '319', '320', 'label'],\n",
       "      dtype='object', length=322)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import esm\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('/home/musong/Desktop/paper/data/drugfinder/esm2_320_dimensions_with_labels.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm_embeddings(peptide_sequence_list):\n",
    "    model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()  # disables dropout for deterministic results\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "    ## batch tokens are the embedding results of the whole data set\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        # Here we export the last layer of the EMS model output as the representation of the peptides\n",
    "        # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
    "        results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
    "    token_representations = results[\"representations\"][6]\n",
    "\n",
    "    # Generate per-sequence representations via averaging\n",
    "    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append((peptide_sequence_list[i][0], token_representations[i, 1 : tokens_len - 1].mean(0)))\n",
    "    return sequence_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Q9H2Y9',\n",
       "  tensor([-2.9326e-02, -7.5480e-02,  1.5323e-01,  2.2830e-01,  2.7175e-02,\n",
       "           1.4604e-02, -2.1099e-02,  4.4349e-02, -1.1190e-02, -1.4053e-01,\n",
       "           1.7994e-01,  2.0112e-01, -5.4789e-02,  8.6889e-02,  1.1479e-01,\n",
       "          -1.4297e-01, -9.6325e-02,  5.1462e-02,  2.3146e-02,  8.7105e-02,\n",
       "          -1.0492e-01, -7.3735e-02,  6.3370e-02,  8.6488e-02,  6.0477e-03,\n",
       "           2.7618e-01,  3.6619e-02, -1.9149e-03,  1.1605e-01,  2.3564e-01,\n",
       "          -5.1230e-02,  1.1305e-02,  1.6400e-01, -2.3677e-01,  1.5775e-01,\n",
       "          -2.7568e-01,  1.6861e-01,  1.2491e-01,  5.2414e-02,  1.1218e-01,\n",
       "          -8.4583e-02,  2.8117e-02,  2.4195e-01,  9.7498e-02, -8.7013e-02,\n",
       "           1.8309e-02, -8.8874e-01,  1.8250e-01,  1.1422e-02, -1.0467e-01,\n",
       "           1.5478e-02,  5.6556e-02, -8.5190e-02,  1.5708e-01, -2.1839e-01,\n",
       "          -2.7518e-01,  1.5420e-01, -9.3446e-02,  8.1160e-02, -2.8677e-01,\n",
       "           1.6532e-02, -5.2077e-03, -4.0684e+00, -2.5211e-01,  1.1528e-01,\n",
       "          -1.0036e-01, -7.8250e-02,  2.7805e-01, -1.0304e-01,  5.1424e-03,\n",
       "          -3.7491e-01,  9.2300e-02, -5.8276e-02,  8.9647e-02, -9.4761e-02,\n",
       "           7.1334e-03,  4.9139e-02, -2.2140e-02, -2.0230e-02,  8.7355e-02,\n",
       "           1.2369e-01,  6.8655e-02,  7.4937e-02,  1.2715e-01,  1.6203e-02,\n",
       "          -2.0298e-01,  1.2155e-01, -7.1893e-02, -1.2456e-01,  3.4377e-02,\n",
       "          -1.4303e-01, -1.1386e-01, -8.3858e-02,  4.9094e-02, -2.1590e-01,\n",
       "           1.8323e-01,  2.8044e-02,  2.5600e-02, -6.9022e-02, -5.0079e-02,\n",
       "           2.7617e-01,  5.0277e-02, -9.2706e-02,  5.3961e-02,  3.8733e-02,\n",
       "           2.3562e-01, -1.9116e-01, -1.7365e-02, -1.5265e-02,  9.7536e-02,\n",
       "          -5.0878e-03, -3.2670e-02,  2.0507e-01,  4.5392e-02, -1.1199e-01,\n",
       "           1.2097e-02,  8.8871e-02,  1.4326e-01, -8.8137e-02,  1.3739e-01,\n",
       "           9.4392e-02,  2.2030e-01,  1.0805e-01,  1.4827e-01,  2.0985e-02,\n",
       "          -7.9777e-02, -2.1157e-01, -2.0635e-01, -2.6991e-01,  1.5900e-01,\n",
       "          -1.8572e-02, -9.2369e-03,  1.1540e-02, -5.9777e-02,  2.8096e-01,\n",
       "           5.8051e-02, -2.0698e-01,  3.3462e-02, -2.1482e-01, -1.3184e-01,\n",
       "           1.1313e-01, -1.3770e-01, -4.8568e-02, -1.0267e-01, -2.1272e-01,\n",
       "           3.9044e-03, -1.6161e-01,  2.1686e-01, -1.1783e-01,  2.2290e-01,\n",
       "          -4.2974e-03, -2.6754e-02, -5.6222e-02, -2.8993e-01,  1.9665e-02,\n",
       "           1.8382e-01, -4.9220e-02, -1.0497e-02, -8.1350e-02,  7.7846e-02,\n",
       "          -1.5987e-01, -2.0666e-02,  1.6339e-01, -1.1531e-01, -3.0986e-02,\n",
       "           1.4432e-01,  7.1116e-02, -1.6364e-01,  2.0318e-02,  6.4847e-03,\n",
       "           1.8366e-01, -6.0863e-03,  3.5393e-02,  4.7885e-02, -1.1829e-01,\n",
       "           1.3675e-01,  1.2592e-01, -1.2971e-01,  2.0388e-01, -2.8130e-01,\n",
       "           1.1643e-01, -3.0779e-01,  2.9344e-02, -3.6231e-02, -3.8239e-02,\n",
       "           1.1772e-01, -3.0000e-01,  2.4266e-01, -7.0471e-04, -1.4795e-01,\n",
       "          -8.8155e-02,  2.4718e-01,  4.2200e-01,  7.1583e-02,  1.0080e-01,\n",
       "           8.2928e-02, -8.9506e-02,  6.9929e-02,  1.4234e-01,  1.4532e-01,\n",
       "          -8.1614e-02,  2.8154e-01,  9.7154e-02,  6.0225e-02, -5.4455e-02,\n",
       "           1.2292e-01, -1.4614e-01,  3.1403e-02,  1.1021e-02,  3.2367e-02,\n",
       "          -8.7940e-02, -6.4039e-02, -2.1071e-01,  3.6881e-02, -1.5132e-02,\n",
       "           8.8532e-02, -1.0139e-01, -6.1155e-02, -1.5764e-01, -6.4926e-02,\n",
       "          -2.9649e-01, -9.9950e-02,  1.8558e-01,  2.2769e-02,  7.7719e-02,\n",
       "           2.6851e-03, -1.3475e-01, -1.5360e-01,  5.9803e-02, -6.3898e-02,\n",
       "           7.9799e-03,  6.9943e-02,  8.6795e-02, -9.6297e-02,  1.9832e-01,\n",
       "           7.8751e-02, -2.5009e-01, -1.0746e-02,  7.3366e-02,  4.4897e-02,\n",
       "          -1.0284e-01,  2.7959e-02,  3.8557e-02,  5.2649e-02,  1.5540e-03,\n",
       "          -2.7789e-02,  3.0577e-01,  4.1860e-02,  2.2412e-01, -1.5326e-01,\n",
       "          -1.5854e-01, -1.8592e-01,  1.3704e-01, -6.9603e-02, -1.2716e-01,\n",
       "           9.9624e-02, -9.3578e-02,  4.2827e-02,  1.2766e-01,  1.6091e-01,\n",
       "           5.1628e-02, -5.7044e-02, -1.8770e-01, -1.3317e-01,  1.9020e-02,\n",
       "           9.1423e-02, -3.0403e-01, -1.9609e-01,  1.0947e-01,  5.4530e-03,\n",
       "          -6.6624e-02,  1.5789e-01,  3.3952e-02,  2.5358e-01,  4.9543e-02,\n",
       "           5.3814e-03, -1.1187e-02, -1.0457e-01, -2.2972e-02,  2.6247e-02,\n",
       "           1.0741e-01, -6.5670e-02,  3.3348e-01, -2.4783e-02,  2.5519e-01,\n",
       "           3.5868e-01, -1.6014e-01,  1.4632e-01, -3.1613e-02, -4.0389e-02,\n",
       "          -2.0827e-01, -1.5486e-01,  1.2284e-01,  2.1965e-01,  2.0395e-02,\n",
       "           2.2083e-02, -1.4919e-01,  6.7133e-03, -2.7507e-01,  1.7209e-01,\n",
       "          -5.0711e-02,  2.3515e-02,  5.0856e-02,  2.4971e-01, -4.1157e-02,\n",
       "          -2.8209e-01, -8.0754e-02, -1.4150e-01, -1.8585e-01, -9.8164e-02,\n",
       "           4.7317e-02,  3.5485e-02,  5.3716e-02,  4.9549e-02, -1.6788e-01,\n",
       "          -2.2310e-01, -9.1271e-02,  1.1894e-01, -1.6912e-01,  1.7850e-01],\n",
       "         device='cuda:0'))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Q9H2Y9'\n",
    "b = \"\"\"\n",
    "MDEGTGLQPGAGEQLEAPATAEAVQERCEPETLRSKSLPVLSSASCRPSLSPTSGDANPAFGCVDSSGHQELKQGPNPLAPSPSAPSTSAGLGDCNHRVDLSKTFSVSSALAMLQERRCLYVVLTDSRCFLVCMCFLTFIQALMVSGYLSSVITTIERRYSLKSSESGLLVSCFDIGNLVVVVFVSYFGGRGRRPLWLAVGGLLIAFGAALFALPHFISPPYQIQELNASAPNDGLCQGGNSTATLEPPACPKDSGGNNHWVYVALFICAQILIGMGSTPIYTLGPTYLDDNVKKENSSLYLAIMYVMGALGPAVGYLLGGLLIGFYVDPRNPVHLDQNDPRFIGNWWSGFLLCAIAMFLVIFPMFTFPKKLPPRHKKKKKKKFSVDAVSDDDVLKEKSNNSEQADKKVSSMGFGKDVRDLPRAAVRILSNMTFLFVSLSYTAESAIVTAFITFIPKFIESQFGIPASNASIYTGVIIVPSAGVGIVLGGYIIKKLKLGARESAKLAMICSGVSLLCFSTLFIVGCESINLGGINIPYTTGPSLTMPHRNLTGSCNVNCGCKIHEYEPVCGSDGITYFNPCLAGCVNSGNLSTGIRNYTECTCVQSRQVITPPTVGQRSQLRVVIVKTYLNENGYAVSGKCKRTCNTLIPFLVFLFIVTFITACAQPSAIIVTLRSVEDEERPFALGMQFVLLRTLAYIPTPIYFGAVIDTTCMLWQQECGVQGSCWEYNVTSFRFVYFGLAAGLKFVGFIFIFLAWYSIKYKEDGLQRRRQREFPLSTVSERVGHPDNARTRSCPAFSTQGEFHEETGLQKGIQCAAQTYPGPFPEAISSSADPGLEESPAALEPPS\n",
    "\"\"\"\n",
    "esm_embeddings([(a, b)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
