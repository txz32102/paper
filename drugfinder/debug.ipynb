{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UniProt_id', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '312', '313', '314', '315', '316', '317', '318', '319', '320', 'label'],\n",
       "      dtype='object', length=322)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import esm\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('/home/musong/Desktop/paper/data/drugfinder/esm2_320_dimensions_with_labels.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm_embeddings(peptide_sequence_list):\n",
    "    model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()  # disables dropout for deterministic results\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "    ## batch tokens are the embedding results of the whole data set\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        # Here we export the last layer of the EMS model output as the representation of the peptides\n",
    "        # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
    "        results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
    "    token_representations = results[\"representations\"][6]\n",
    "\n",
    "    # Generate per-sequence representations via averaging\n",
    "    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append((peptide_sequence_list[i][0], token_representations[i, 1 : tokens_len - 1].mean(0)))\n",
    "    return sequence_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('P50579',\n",
       "  tensor([ 2.0595e-02, -5.2397e-02,  7.2424e-02,  2.4903e-01,  1.3683e-01,\n",
       "          -9.5064e-03,  7.8911e-02, -1.1505e-01, -7.1237e-02, -9.5962e-02,\n",
       "           1.1693e-03,  1.7169e-02, -1.6200e-01,  8.7022e-02,  1.3806e-01,\n",
       "          -1.6597e-01, -1.1243e-02, -1.6501e-01,  4.9552e-02,  1.8117e-01,\n",
       "           1.8462e-02, -2.2816e-02, -4.0338e-02, -1.8552e-01,  1.2977e-01,\n",
       "           1.6385e-01, -1.7089e-02,  4.1195e-02, -2.1177e-02,  8.2126e-02,\n",
       "          -3.0474e-02,  1.2641e-01,  3.9872e-02, -2.6634e-01, -2.6091e-02,\n",
       "          -7.0616e-02,  2.6442e-02,  3.9284e-02,  1.6439e-01,  1.3452e-01,\n",
       "           7.6915e-02,  2.6355e-01, -1.4124e-01,  3.5976e-02, -6.2721e-02,\n",
       "           7.8290e-02, -1.1267e+00,  9.4312e-02, -2.9280e-01, -7.1302e-02,\n",
       "           4.6619e-02, -3.7156e-02,  4.1510e-02,  6.6509e-02, -4.5167e-02,\n",
       "          -1.5195e-01,  2.0540e-01, -3.1420e-02,  4.3970e-01, -2.0260e-02,\n",
       "          -4.1587e-03,  9.1296e-03, -4.5462e+00, -1.4220e-01, -1.8296e-02,\n",
       "           3.2205e-03,  7.8405e-02,  1.2432e-01,  8.7651e-02,  5.5014e-02,\n",
       "          -2.1580e-01, -6.1671e-03, -4.6456e-02,  2.3823e-01, -1.2384e-01,\n",
       "           9.1749e-02, -5.1973e-02,  1.7982e-03, -3.7632e-02,  2.3063e-02,\n",
       "           1.3774e-01,  6.4006e-02,  1.6079e-02, -3.1976e-02,  6.6812e-02,\n",
       "          -9.4546e-02,  1.3298e-01, -2.4221e-01,  1.2456e-01,  1.6778e-01,\n",
       "          -1.6336e-01,  2.3957e-02,  9.7683e-02,  1.9524e-01,  6.6007e-03,\n",
       "           1.0190e-01, -2.3471e-02, -8.3558e-02, -5.2086e-02, -5.6089e-02,\n",
       "           2.1774e-01, -6.5961e-02, -1.4252e-01,  2.7456e-01, -9.0039e-02,\n",
       "           7.5804e-02, -8.7728e-03,  1.2035e-01, -1.6022e-01, -1.7706e-02,\n",
       "           5.0468e-02,  1.8059e-02, -3.3250e-02,  3.2779e-02,  1.7092e-01,\n",
       "           1.0915e-01,  6.0135e-02,  1.3492e-01, -1.7103e-01,  2.7069e-03,\n",
       "          -1.5012e-02,  1.8992e-01,  1.9221e-01,  9.3555e-02,  1.2806e-01,\n",
       "          -4.8679e-02, -3.3586e-02, -9.5503e-02, -1.1202e-01,  1.5110e-01,\n",
       "          -8.3331e-02, -7.6987e-02, -2.9101e-01,  8.8529e-02,  2.1961e-01,\n",
       "           1.7282e-02, -1.5752e-01, -1.0888e-01, -5.9265e-02, -2.2976e-01,\n",
       "           1.2833e-01, -9.0268e-02,  4.9765e-02,  2.2156e-01, -5.7705e-02,\n",
       "          -1.3137e-01,  9.4717e-02,  1.8306e-01, -2.0828e-01,  2.0482e-01,\n",
       "           1.6384e-01, -9.3376e-02, -1.4486e-01, -2.4290e-01, -1.7186e-01,\n",
       "           3.6282e-02,  7.4021e-02,  2.1368e-01, -5.9219e-02,  7.3197e-02,\n",
       "          -4.8932e-02, -1.2182e-01,  4.6131e-02,  9.6919e-02,  4.0893e-02,\n",
       "           8.3809e-02,  1.2354e-01, -1.6241e-01, -6.0030e-02,  7.7823e-02,\n",
       "          -1.1580e-01,  2.2271e-02,  1.6506e-01, -1.0404e-01, -4.0923e-02,\n",
       "           8.8402e-02,  2.1211e-01, -9.9264e-02, -2.2314e-01, -2.0390e-02,\n",
       "           2.1602e-01,  6.7962e-04, -1.0564e-02,  7.3005e-02, -9.5098e-02,\n",
       "           1.1085e-01, -1.7071e-01,  1.9952e-01,  8.8009e-02, -1.6709e-01,\n",
       "           7.7228e-03,  9.5542e-02,  3.6544e-01,  1.4055e-01, -1.3770e-01,\n",
       "           4.3699e-02, -2.4518e-01,  1.2330e-01,  6.9433e-02,  1.9979e-01,\n",
       "          -7.1353e-02,  1.9950e-01,  2.8504e-02,  6.7280e-02, -1.4046e-01,\n",
       "           1.0232e-01,  4.7275e-02,  1.1140e-01,  7.6582e-02,  6.3260e-02,\n",
       "          -2.8436e-02, -2.0334e-01, -4.6121e-02,  8.6262e-02,  2.1663e-02,\n",
       "           1.8181e-02, -1.0731e-01, -2.1510e-02,  3.4996e-02,  4.1079e-02,\n",
       "          -1.5489e-01, -4.5788e-02,  5.8590e-02,  1.1176e-01, -5.6295e-02,\n",
       "          -1.6529e-01, -8.6219e-02, -6.1978e-02,  7.8172e-03, -2.9443e-02,\n",
       "           7.8628e-03, -2.3645e-02,  1.2038e-02,  1.1744e-02,  1.0105e-01,\n",
       "          -7.4432e-02,  6.9072e-02, -7.7943e-02, -6.5190e-03,  4.9315e-04,\n",
       "           1.6925e-02, -1.7044e-01,  1.5236e-02, -6.3134e-02,  2.2028e-01,\n",
       "          -7.0267e-02,  1.5110e-01,  3.2945e-03,  1.1203e-01, -1.9799e-01,\n",
       "          -2.3813e-01,  3.7725e-02, -6.5863e-02,  1.0848e-01, -9.1184e-02,\n",
       "           1.8769e-01, -6.2885e-02, -3.0062e-02,  6.5140e-02, -4.4082e-02,\n",
       "          -1.5493e-02, -1.1455e-01, -2.7793e-02, -1.4037e-01, -8.4911e-03,\n",
       "           1.5506e-01, -4.2265e-02, -9.3245e-02,  1.9518e-01, -4.8207e-02,\n",
       "           2.0133e-01, -4.0613e-02,  1.0890e-01,  9.4964e-02,  8.1811e-02,\n",
       "          -6.2293e-02,  8.6758e-02, -3.9470e-02, -7.9313e-02, -1.1238e-01,\n",
       "           7.7672e-02, -7.7186e-02,  2.8795e-01, -4.5621e-02,  5.0184e-02,\n",
       "           2.2692e-01, -1.4260e-01,  5.7076e-02, -1.4055e-01,  1.0640e-03,\n",
       "          -1.3664e-01, -1.4118e-01,  1.1859e-01, -1.5150e-02,  2.0788e-02,\n",
       "          -3.7985e-02, -1.6091e-01, -4.1826e-02, -2.6813e-01,  1.7662e-01,\n",
       "          -1.0333e-01,  1.2724e-02,  1.1068e-01, -2.2537e-02, -3.7089e-02,\n",
       "          -2.6430e-02,  9.9419e-02, -1.2553e-01,  8.1820e-02, -1.7793e-01,\n",
       "          -4.4681e-02, -5.2008e-02, -1.3452e-01,  8.4746e-02,  4.9206e-02,\n",
       "          -1.8337e-01, -8.4628e-02,  3.5126e-02, -1.6605e-02, -2.7334e-02],\n",
       "         device='cuda:0'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'P50579'\n",
    "b = \"\"\"\n",
    "MAGVEEVAASGSHLNGDLDPDDREEGAASTAEEAAKKKRRKKKKSKGPSAAGEQEPDKESGASVDEVARQLERSALEDKERDEDDEDGDGDGDGATGKKKKKKKKKRGPKVQTDPPSVPICDLYPNGVFPKGQECEYPPTQDGRTAAWRTTSEEKKALDQASEEIWNDFREAAEAHRQVRKYVMSWIKPGMTMIEICEKLEDCSRKLIKENGLNAGLAFPTGCSLNNCAAHYTPNAGDTTVLQYDDICKIDFGTHISGRIIDCAFTVTFNPKYDTLLKAVKDATNTGIKCAGIDVRLCDVGEAIQEVMESYEVEIDGKTYQVKPIRNLNGHSIGQYRIHAGKTVPIVKGGEATRMEEGEVYAIETFGSTGKGVVHDDMECSHYMKNFDVGHVPIRLPRTKHLLNVINENFGTLAFCRRWLDRLGESKYLMALKNLCDLGIVDPYPPLCDIKGSYTAQFEHTILLRPTCKEVVSRGDDY\n",
    "\"\"\"\n",
    "esm_embeddings([(a, b)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
